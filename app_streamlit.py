import streamlit as st
import os
from llama_cloud_services import LlamaParse
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
import openai


st.set_page_config(page_title="PDF Chat App", layout="wide")

# 2ë‹¨ ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ (ì™¼ìª½: ì±„íŒ…, ì˜¤ë¥¸ìª½: íŒŒì¼ ì—…ë¡œë“œ)
col_chat, col_upload = st.columns([2, 1])

# FAISS DBë¥¼ ì„¸ì…˜ì— ì €ì¥
if "faiss_db" not in st.session_state:
    st.session_state["faiss_db"] = None

with col_chat:
    st.header("ğŸ’¬ êµìœ¡ ìë£Œ ê²€ìƒ‰í•˜ê¸°")
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []
    # ì±„íŒ… ë‚´ì—­ í‘œì‹œ
    for msg in st.session_state["chat_history"]:
        st.markdown(f"**{msg['role']}**: {msg['content']}")
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="user_input")
    if st.button("ì „ì†¡"):
        if user_input:
            st.session_state["chat_history"].append(
                {"role": "user", "content": user_input}
            )
            st.session_state["user_input"] = ""  # ì…ë ¥ì°½ ì´ˆê¸°í™”
    # ê²€ìƒ‰ ë²„íŠ¼ ë° ê²°ê³¼ ì¶œë ¥
    if st.button("ê²€ìƒ‰"):
        if st.session_state["faiss_db"] is not None and user_input:
            retriever = st.session_state["faiss_db"].as_retriever(
                search_type="similarity", search_kwargs={"k": 5}
            )
            # invokeê°€ (doc, score) íŠœí”Œì„ ë°˜í™˜í•˜ë„ë¡ ê°€ì •
            results = retriever.invoke(user_input, return_score=True)

            # í—¤ë” ê°€ì¤‘ì¹˜ ì ìš© í•¨ìˆ˜
            def custom_score(doc, query, base_score):
                header_text = doc.metadata.get("header_text", "")
                if query in header_text:
                    return base_score + 0.2  # í—¤ë”ì— í¬í•¨ë˜ë©´ 0.2ì  ì¶”ê°€
                return base_score

            # í—¤ë” ê°€ì¤‘ì¹˜ ì ìš© ë° ì •ë ¬
            scored_results = [
                (doc, custom_score(doc, user_input, score)) for doc, score in results
            ]
            scored_results.sort(key=lambda x: x[1], reverse=True)
            st.subheader("ê²€ìƒ‰ ê²°ê³¼ (í—¤ë” ê°€ì¤‘ì¹˜ ì ìš©)")
            for i, (doc, score) in enumerate(scored_results):
                st.markdown(f"**ê²°ê³¼ {i+1} (ì ìˆ˜: {score:.3f})**")
                st.code(doc.page_content)
                st.json(doc.metadata)
        else:
            st.warning("ë¨¼ì € FAISSì— ì„ë² ë”©ì„ ì €ì¥í•˜ê³ , ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

with col_upload:
    st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])
    if uploaded_file:
        st.info("íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ íŒŒì‹±ì„ ì‹œì‘í•˜ì„¸ìš”.")
        output_dir = "temp_output"
        os.makedirs(output_dir, exist_ok=True)
        md_save_path = os.path.join(
            output_dir, f"temp_{os.path.splitext(uploaded_file.name)[0]}.md"
        )
        # ì´ë¯¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ìˆìœ¼ë©´ llama parserë¥¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        if os.path.exists(md_save_path):
            st.info(f"ì´ë¯¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤: {md_save_path}")
            st.session_state["md_save_path"] = md_save_path
        elif st.button("íŒŒì‹± ì‹œì‘"):
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_pdf_path = os.path.join(output_dir, f"temp_{uploaded_file.name}")
            with open(temp_pdf_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            # llama parser ì‹¤í–‰
            parser_obj = LlamaParse(
                api_key=os.getenv("LLAMA_CLOUD_API_KEY"),
                num_workers=1,
                verbose=True,
                language="ko",
                extract_layout=True,
                premium_mode=True,
                continuous_mode=False,
                extract_charts=True,
                save_images=True,
                output_tables_as_HTML=False,
                max_pages=6,
            )
            st.info("llama_parse ì‹¤í–‰ ì¤‘...")
            result = parser_obj.parse(temp_pdf_path)
            md_docs = result.get_markdown_documents()
            st.session_state["md_docs"] = md_docs  # ì„¸ì…˜ì— ì €ì¥
            st.success("ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„± ì™„ë£Œ!")
            if md_docs:
                # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
                with open(md_save_path, "w", encoding="utf-8") as f:
                    for doc in md_docs:
                        f.write(doc.text)
                st.session_state["md_save_path"] = md_save_path
                st.info(f"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {md_save_path}")
        elif "md_docs" in st.session_state:
            st.success("ì´ì „ íŒŒì‹± ê²°ê³¼:")
            # ë¯¸ë¦¬ë³´ê¸°ëŠ” ì œê³µí•˜ì§€ ì•ŠìŒ

    # ì„ë² ë”© ë° FAISS ì €ì¥ ë²„íŠ¼
    if "md_save_path" in st.session_state and st.button("ì„ë² ë”© ë° FAISS ì €ì¥"):
        md_save_path = st.session_state["md_save_path"]
        with open(md_save_path, "r", encoding="utf-8") as f:
            md_text = f.read()
        # 1. Split
        headers_to_split_on = [
            ("#", "Header 1"),
            ("##", "Header 2"),
            ("###", "Header 3"),
        ]
        markdown_splitter = MarkdownHeaderTextSplitter(
            headers_to_split_on=headers_to_split_on
        )
        md_header_splits = markdown_splitter.split_text(md_text)
        # ê° chunkì— header_text í•„ë“œ ì¶”ê°€
        for chunk in md_header_splits:
            headers = [v for k, v in chunk.metadata.items() if k.startswith("Header")]
            chunk.metadata["header_text"] = " ".join(headers)
        # 2. ì„ë² ë”©
        embeddings = OpenAIEmbeddings()
        # 3. FAISS ë²¡í„° DB ì €ì¥
        db = FAISS.from_documents(md_header_splits, embeddings)
        st.session_state["faiss_db"] = db  # ì„¸ì…˜ì— ì €ì¥
        st.success(
            f"{len(md_header_splits)}ê°œ chunkê°€ ì„ë² ë”©ë˜ì–´ FAISSì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
