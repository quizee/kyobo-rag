import streamlit as st
import os
from dotenv import load_dotenv
import nest_asyncio
import re
from PIL import Image
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor

from PIL import Image as PILImage
from pptx.enum.text import PP_ALIGN
import time
import pandas as pd


nest_asyncio.apply()
from llama_cloud_services import LlamaParse
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
import openai
import json
from scripts.clova_ocr_utils import ocr_image
import requests
from scripts.upstage_parser import UpstageParser

# .env í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

st.set_page_config(page_title="PDF Chat App", layout="wide")


def crop_image_by_y(
    image_path, y_start, y_end, output_path, margin_top=15, margin_side=30
):
    """ì´ë¯¸ì§€ë¥¼ y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ëŠ” í•¨ìˆ˜"""
    try:
        img = Image.open(image_path)
        img_width, img_height = img.size

        # ì—¬ë°± ì ìš© (ë¶€ë™ì†Œìˆ˜ì  ìœ ì§€)
        y_start = max(0, y_start - margin_top)
        y_end = min(img_height, y_end)
        x_start = max(0, margin_side)
        x_end = min(img_width, img_width - margin_side)

        if y_end <= y_start or x_end <= x_start:
            print("Invalid crop dimensions")
            return None

        # ìµœì¢…ì ìœ¼ë¡œ ì •ìˆ˜ë¡œ ë³€í™˜ (ì´ë¯¸ì§€ í¬ë¡­ ì‹œì—ë§Œ)
        crop_box = (int(x_start), int(y_start), int(x_end), int(y_end))
        cropped = img.crop(crop_box)
        cropped.save(output_path)
        return output_path
    except Exception as e:
        print(f"Error cropping image: {str(e)}")
        return None


def is_useless_header(text):
    # í•œê¸€ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ False
    if re.search(r"[ê°€-í£]", text):
        return False
    # í•œê¸€ì´ ì—†ê³ , ìˆ«ì/ì˜ì–´/ê³µë°±/íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆìœ¼ë©´ True
    if re.fullmatch(r"[\dA-Za-z\s\W]+", text):
        return True
    return False


def build_header_dictionary(headers, _, output_dir="temp_output"):
    """
    headers: [{page, level, text, y, bbox}, ...]
    return: {"header_text": {page, level, text, y, crop_image_path, Header 1, Header 2, Header 3}}
    """
    header_dict = {}
    from collections import defaultdict

    # í˜ì´ì§€ë³„ë¡œ ê·¸ë£¹í™” (1í˜ì´ì§€ ì œì™¸)
    page_to_headers = defaultdict(list)
    for header in headers:
        if (
            header["y"] is not None and header["page"] > 1
        ):  # y ì¢Œí‘œê°€ ìˆê³  1í˜ì´ì§€ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
            page_to_headers[header["page"]].append(header)

    # ê° í˜ì´ì§€ë³„ë¡œ í—¤ë” ì •ë³´ ìˆ˜ì§‘ (1í˜ì´ì§€ ì œì™¸)
    for page_number, page_headers_list in page_to_headers.items():
        if page_number <= 1:  # 1í˜ì´ì§€ëŠ” ê±´ë„ˆë›°ê¸°
            continue

        # yì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_headers = sorted(page_headers_list, key=lambda x: x["y"])

        # í˜„ì¬ í˜ì´ì§€ì˜ í—¤ë” ê³„ì¸µ êµ¬ì¡° ì¶”ì 
        current_headers = {1: "", 2: "", 3: ""}  # Header 1  # Header 2  # Header 3

        for header in sorted_headers:
            level = header["level"]
            text = header["text"]

            # í˜„ì¬ ë ˆë²¨ì˜ í—¤ë” ì—…ë°ì´íŠ¸
            current_headers[level] = text

            # ìƒìœ„ ë ˆë²¨ì˜ í—¤ë” ì •ë³´ ìœ ì§€
            for l in range(level + 1, 4):
                current_headers[l] = ""

            # í—¤ë” ì •ë³´ ì €ì¥
            key = f"{text}"
            header_dict[key] = {
                "page": page_number,
                "level": level,
                "text": text,
                "markdown_text": header.get("markdown_text", f"{'#' * level} {text}"),
                "y": header["y"],
                "crop_image_path": None,  # ë‚˜ì¤‘ì— ì„¤ì •ë¨
                "Header 1": current_headers[1],
                "Header 2": current_headers[2],
                "Header 3": current_headers[3],
                "page_number": page_number,
                "bbox": header.get("bbox"),
            }

    # ê° í˜ì´ì§€ì˜ í—¤ë”ë³„ë¡œ ì´ë¯¸ì§€ ìƒì„±
    for page_number, page_headers_list in page_to_headers.items():
        page_img_path = os.path.join(output_dir, f"page_{page_number}.jpg")

        # í˜ì´ì§€ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ PDFì—ì„œ ë³€í™˜
        if not os.path.exists(page_img_path):
            print(f"Page image not found: {page_img_path}, converting from PDF...")
            # PDF íŒŒì¼ ì°¾ê¸°
            pdf_files = [
                f
                for f in os.listdir(output_dir)
                if f.startswith("temp_") and f.endswith(".pdf")
            ]
            if not pdf_files:
                print("No PDF file found in output directory")
                continue

            pdf_path = os.path.join(output_dir, pdf_files[0])
            # í˜„ì¬ í˜ì´ì§€ë§Œ ë³€í™˜
            try:
                import fitz  # PyMuPDF

                doc = fitz.open(pdf_path)
                if page_number <= len(doc):
                    page = doc[page_number - 1]  # 0-based index
                    pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72))
                    pix.save(page_img_path)
                    print(f"Converted page {page_number} to image: {page_img_path}")
                doc.close()
            except Exception as e:
                print(f"Error converting page {page_number} to image: {str(e)}")
                continue

        if not os.path.exists(page_img_path):
            print(f"Warning: Page image not found after conversion: {page_img_path}")
            continue

        print(f"Processing page {page_number}, image path: {page_img_path}")
        img = Image.open(page_img_path)
        img_width, img_height = img.size
        print(f"Image size: {img.size}")

        # ëª¨ë“  í—¤ë”ë¥¼ yì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        all_headers = sorted(page_headers_list, key=lambda h: h["y"])
        print(f"Total headers on page {page_number}: {len(all_headers)}")

        # ê° í—¤ë”ì— ëŒ€í•´ ì´ë¯¸ì§€ ìƒì„±
        for i, header in enumerate(all_headers):
            # í˜„ì¬ í—¤ë”ì˜ y ì¢Œí‘œ (ìƒëŒ€ê°’ì„ í”½ì…€ê°’ìœ¼ë¡œ ë³€í™˜)
            y_start = header["y"] * img_height  # ì •ìˆ˜ ë³€í™˜í•˜ì§€ ì•Šê³  ë¶€ë™ì†Œìˆ˜ì  ìœ ì§€

            # ë‹¤ìŒ í—¤ë”ì˜ y ì¢Œí‘œ ì°¾ê¸° (í—¤ë” ë ˆë²¨ ê³ ë ¤)
            y_end = img_height  # ê¸°ë³¸ê°’ì€ í˜ì´ì§€ ë
            current_header_text = header["text"]
            current_header_level = header["level"]

            for next_header in all_headers[i + 1 :]:
                next_y = next_header["y"] * img_height
                if next_y > y_start:  # í˜„ì¬ í—¤ë”ë³´ë‹¤ ì•„ë˜ì— ìˆëŠ” í—¤ë”
                    if next_header["level"] == current_header_level:
                        y_end = next_y
                        break

            print(
                f"Header {i+1}: y_start={y_start:.2f}, y_end={y_end:.2f}, text={header['text'][:20]}..."
            )

            if y_end <= y_start:
                print(f"Skipping header {i+1}: invalid y coordinates")
                continue

            # ì´ë¯¸ì§€ ì—¬ë°± ê³„ì‚° (ì´ë¯¸ì§€ í¬ê¸°ì— ë¹„ë¡€)
            margin_top = img_height * 0.02  # ìƒë‹¨ ì—¬ë°± 2%
            margin_side = img_width * 0.05  # ì¢Œìš° ì—¬ë°± 5%

            # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ìˆëŠ” ê²½ìš°, ì¢Œìš° ì—¬ë°±ì„ ë°”ìš´ë”© ë°•ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì¡°ì •
            if header.get("bbox"):
                bbox = header["bbox"]
                try:
                    # ì¢Œìš° ì¢Œí‘œë¥¼ í”½ì…€ê°’ìœ¼ë¡œ ë³€í™˜
                    left_x = bbox["top_left"]["x"] * img_width
                    right_x = bbox["top_right"]["x"] * img_width
                    # ë°”ìš´ë”© ë°•ìŠ¤ ë„ˆë¹„ì˜ 5%ë¥¼ ì—¬ë°±ìœ¼ë¡œ ì‚¬ìš©
                    margin_side = (right_x - left_x) * 0.05
                except (KeyError, TypeError):
                    # bbox êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥´ê±°ë‚˜ Noneì¸ ê²½ìš° ê¸°ë³¸ ì—¬ë°± ì‚¬ìš©
                    margin_side = img_width * 0.05

            out_path = os.path.join(
                output_dir,
                f"page_{page_number}_level{header['level']}_header_{i+1}_{header['text'].replace('#', '').strip()}.jpg",
            )

            # ì´ë¯¸ í¬ë¡­ëœ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
            if os.path.exists(out_path):
                print(f"Using existing cropped image: {out_path}")
            else:
                print(f"Cropping image to: {out_path}")
                crop_result = crop_image_by_y(
                    page_img_path,
                    y_start,
                    y_end,
                    out_path,
                    margin_top=margin_top,
                    margin_side=margin_side,
                )
                if crop_result is None:
                    print(f"Failed to crop image for header {i+1}")
                    continue
                print(f"Successfully cropped image: {out_path}")

            # í—¤ë” ì •ë³´ ì—…ë°ì´íŠ¸
            header_dict[current_header_text]["crop_image_path"] = out_path

    print(f"Total headers processed: {len(header_dict)}")
    return header_dict


def add_source_text(slide, header_info, prs, pdf_name=""):
    """í•˜ë‹¨ ì¤‘ì•™ì— ì¶œì²˜ í…ìŠ¤íŠ¸ ì¶”ê°€"""
    # page_numberë¥¼ header_infoì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (page ë˜ëŠ” page_number í‚¤ ì‚¬ìš©)
    page_number = header_info.get("page_number") or header_info.get("page", "?")

    # ì¶œì²˜ í…ìŠ¤íŠ¸ ë°•ìŠ¤
    width = Inches(6)  # ê³ ì •ëœ ë„ˆë¹„
    left = (prs.slide_width - width) / 2  # ì¤‘ì•™ ì •ë ¬
    top = prs.slide_height - Inches(1.2)  # AI ê³ ì§€ ë¬¸êµ¬ ìœ„ì— ìœ„ì¹˜
    height = Inches(0.5)

    ref_box = slide.shapes.add_textbox(left, top, width, height)
    ref_tf = ref_box.text_frame
    ref_tf.word_wrap = True

    p_ref = ref_tf.paragraphs[0]
    p_ref.alignment = PP_ALIGN.CENTER

    run1 = p_ref.add_run()
    run1.text = "[ì¶œì²˜: "
    run1.font.size = Pt(12)
    run1.font.color.rgb = RGBColor(120, 120, 120)

    run2 = p_ref.add_run()
    run2.text = f'"{pdf_name}", {page_number}page]'
    run2.font.size = Pt(12)
    run2.font.color.rgb = RGBColor(120, 120, 120)


def add_header_path(slide, header_info, prs):
    """ì œëª© ìœ„ì— ê³„ì¸µì  í—¤ë” ê²½ë¡œ ì¶”ê°€"""
    # levelê³¼ textë¥¼ ì‚¬ìš©í•´ ê³„ì¸µì  í—¤ë” êµ¬ì„±
    level = header_info.get("level", 0)
    text = header_info.get("text", "")

    # í˜„ì¬ í—¤ë”ì˜ ìƒìœ„ í—¤ë”ë“¤ì„ ì°¾ê¸° ìœ„í•´ pageì™€ yì¢Œí‘œ ì‚¬ìš©
    page = header_info.get("page", 0)
    y = header_info.get("y", 0)

    # ê°™ì€ í˜ì´ì§€ì˜ ëª¨ë“  í—¤ë”ë¥¼ ê°€ì ¸ì™€ì„œ yì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    all_headers = []
    for key, info in st.session_state.get("header_dict", {}).items():
        if info.get("page") == page:
            all_headers.append(info)

    # yì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    all_headers.sort(key=lambda x: x.get("y", 0))

    # í˜„ì¬ í—¤ë”ë³´ë‹¤ ìœ„ì— ìˆëŠ” í—¤ë”ë“¤ ì¤‘ ì§ê³„ ìƒìœ„ í—¤ë”ë§Œ ì°¾ê¸°
    header_text = ""
    for h in all_headers:
        if h.get("y", 0) < y:
            h_level = h.get("level", 0)
            # í˜„ì¬ í—¤ë”ì˜ ì§ê³„ ìƒìœ„ í—¤ë”ë§Œ ì¶”ê°€
            if h_level == level - 1:
                if header_text:
                    header_text += " >> "
                header_text += h.get("text", "")

    # í˜„ì¬ í—¤ë” ì¶”ê°€
    if header_text:
        header_text += " >> " + text
    else:
        header_text = text

    # í—¤ë” ê²½ë¡œ í…ìŠ¤íŠ¸ ë°•ìŠ¤
    left = Inches(0.3)
    top = Inches(0.4)  # ì œëª©ë³´ë‹¤ ë” ìœ„ì— ìœ„ì¹˜
    width = prs.slide_width - Inches(0.6)
    height = Inches(0.5)

    path_box = slide.shapes.add_textbox(left, top, width, height)
    path_tf = path_box.text_frame
    path_tf.word_wrap = True

    p_path = path_tf.paragraphs[0]
    p_path.text = header_text
    p_path.font.size = Pt(12)  # 12ptë¡œ ë³€ê²½
    p_path.font.bold = True
    p_path.font.color.rgb = RGBColor(0, 0, 255)  # íŒŒë€ìƒ‰
    p_path.alignment = PP_ALIGN.LEFT


def add_title_text(slide, header_info, prs):
    """ìƒë‹¨ì— í° ì œëª© ì¶”ê°€"""
    # ê³„ì¸µì  í—¤ë” ê²½ë¡œì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ì¶”ì¶œ
    header_path = header_info.get("text", "")
    if " >> " in header_path:
        title_text = header_path.split(" >> ")[-1]
    else:
        title_text = header_path

    title_left = Inches(0.3)
    title_top = Inches(0.6)
    title_width = prs.slide_width - Inches(0.6)
    title_height = Inches(1)

    title_box = slide.shapes.add_textbox(
        title_left, title_top, title_width, title_height
    )
    title_tf = title_box.text_frame
    title_tf.word_wrap = True

    p_title = title_tf.paragraphs[0]
    p_title.text = title_text
    p_title.font.size = Pt(24)
    p_title.font.bold = True
    p_title.font.color.rgb = RGBColor(80, 80, 80)
    p_title.alignment = PP_ALIGN.LEFT


def add_ai_notice_text(slide, prs):
    """í•˜ë‹¨ ì¤‘ì•™ì— ìƒì„±í˜• AI ê³ ì§€ ë¬¸êµ¬ ì¶”ê°€"""
    bottom_text = (
        "ë³¸ ìë£ŒëŠ” ìƒì„±í˜• AI ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ì¤‘ìš”í•œ ì‚¬ì‹¤ì€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
    )

    box_width = Inches(6)
    bottom_left = (prs.slide_width - box_width) / 2
    bottom_top = prs.slide_height - Inches(0.7)
    bottom_height = Inches(0.5)

    ai_box = slide.shapes.add_textbox(bottom_left, bottom_top, box_width, bottom_height)
    ai_tf = ai_box.text_frame
    ai_tf.word_wrap = True

    p_ai = ai_tf.paragraphs[0]
    p_ai.text = bottom_text
    p_ai.font.size = Pt(12)
    p_ai.font.color.rgb = RGBColor(150, 150, 150)
    p_ai.alignment = PP_ALIGN.CENTER


def add_center_image(slide, header_info, prs):
    """ì¤‘ì•™ì— ì´ë¯¸ì§€ ì¶”ê°€"""
    img_path = header_info.get("crop_image_path")
    if img_path and os.path.exists(img_path):
        with PILImage.open(img_path) as im:
            img_width, img_height = im.size
            slide_width = prs.slide_width
            slide_height = prs.slide_height

            # ìŠ¬ë¼ì´ë“œì˜ 40%ë¥¼ ì´ë¯¸ì§€ ìµœëŒ€ ë†’ì´ë¡œ ì„¤ì •
            max_height = slide_height * 0.4

            # ì´ë¯¸ì§€ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
            img_ratio = img_width / img_height

            # ë†’ì´ ê¸°ì¤€ìœ¼ë¡œ í¬ê¸° ê³„ì‚°
            height = max_height
            width = height * img_ratio

            # ë„ˆë¹„ê°€ ìŠ¬ë¼ì´ë“œ ë„ˆë¹„ì˜ 85%ë¥¼ ë„˜ìœ¼ë©´ ë„ˆë¹„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ê³„ì‚°
            if width > slide_width * 0.85:
                width = slide_width * 0.85
                height = width / img_ratio

            # kyobo_layout2 ì´ë¯¸ì§€ ì•„ë˜, ì¶œì²˜ í…ìŠ¤íŠ¸ ìœ„ì— ìœ„ì¹˜í•˜ë„ë¡ ì„¤ì •
            # kyobo_layout2ëŠ” ìƒë‹¨ì—ì„œ Inches(1.2)ì— ìœ„ì¹˜
            # ì¶œì²˜ í…ìŠ¤íŠ¸ëŠ” í•˜ë‹¨ì—ì„œ Inches(1.2)ì— ìœ„ì¹˜
            layout_margin_top = Inches(1.2)  # kyobo_layout2ì˜ ìƒë‹¨ ì—¬ë°±
            source_margin_bottom = Inches(1.2)  # ì¶œì²˜ í…ìŠ¤íŠ¸ì˜ í•˜ë‹¨ ì—¬ë°±

            # ì´ë¯¸ì§€ë¥¼ kyobo_layout2ì™€ ì¶œì²˜ í…ìŠ¤íŠ¸ ì‚¬ì´ì˜ ì¤‘ì•™ì— ë°°ì¹˜
            available_height = slide_height - layout_margin_top - source_margin_bottom
            top = layout_margin_top + (available_height - height) / 2

            # ê°€ë¡œ ì¤‘ì•™ ì •ë ¬
            left = (slide_width - width) / 2

            slide.shapes.add_picture(img_path, left, top, width, height)


def add_layout_image(slide, prs):
    """ì œëª© ì•„ë˜ì— ë ˆì´ì•„ì›ƒ ì´ë¯¸ì§€ ì¶”ê°€"""
    layout_path = os.path.join("temp_output", "kyobo_layout.jpg")
    if os.path.exists(layout_path):
        with PILImage.open(layout_path) as im:
            img_width, img_height = im.size
            # ìŠ¬ë¼ì´ë“œ ë„ˆë¹„ì˜ 95%ë¡œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            width = prs.slide_width * 0.95
            height = (img_height / img_width) * width

            # ì´ë¯¸ì§€ë¥¼ ê°€ë¡œ ì¤‘ì•™ì— ë°°ì¹˜í•˜ê³ , ì œëª© ì•„ë˜ì— ìœ„ì¹˜ì‹œí‚´
            left = (prs.slide_width - width) / 2
            top = Inches(1.2)  # ì œëª© ì•„ë˜ ìœ„ì¹˜

            slide.shapes.add_picture(layout_path, left, top, width, height)


def add_muscle_image(slide, prs):
    """kyobo_muscle.jpg ì´ë¯¸ì§€ ì¶”ê°€"""
    muscle_path = os.path.join("temp_output", "kyobo_muscle.jpg")
    if os.path.exists(muscle_path):
        # cmë¥¼ EMUë¡œ ë³€í™˜ (1cm = 360000 EMU)
        width_cm = 4.05
        height_cm = 0.97
        width = int(width_cm * 360000)
        height = int(height_cm * 360000)

        # ì •í™•í•œ ìœ„ì¹˜ ì§€ì • (ê°€ë¡œ 20.71cm, ì„¸ë¡œ 17.57cm)
        left = int(20.71 * 360000)  # ê°€ë¡œ ìœ„ì¹˜
        top = int(17.57 * 360000)  # ì„¸ë¡œ ìœ„ì¹˜

        slide.shapes.add_picture(muscle_path, left, top, width, height)


def create_ppt_from_header_dict(header_dict, output_path):
    """header_dictë¥¼ ê¸°ë°˜ìœ¼ë¡œ PPT ìƒì„±"""
    from pptx import Presentation
    from pptx.util import Inches, Pt

    prs = Presentation()
    print(f"Creating PPT with {len(header_dict)} headers")

    # ì œëª© ìŠ¬ë¼ì´ë“œ ì¶”ê°€
    title_slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    title.text = "êµë³´ë§ˆì´í”Œëœê±´ê°•ë³´í—˜"
    subtitle.text = "ë¬¸ì„œ ë¶„ì„ ê²°ê³¼"

    # ê° í—¤ë”ë³„ë¡œ ìŠ¬ë¼ì´ë“œ ì¶”ê°€
    for header_text, header_info in header_dict.items():
        # Header 1(level==1)ì€ PPTì— í¬í•¨í•˜ì§€ ì•ŠìŒ
        if header_info.get("level") == 1:
            continue
        print(f"\nProcessing header: {header_text[:30]}...")
        print(f"Header info: {json.dumps(header_info, indent=2, ensure_ascii=False)}")

        slide_layout = prs.slide_layouts[6]  # ë¹ˆ ìŠ¬ë¼ì´ë“œ ë ˆì´ì•„ì›ƒ ì‚¬ìš©
        slide = prs.slides.add_slide(slide_layout)

        # í—¤ë” ê²½ë¡œ ì¶”ê°€
        add_header_path(slide, header_info, prs)

        # ì œëª© ì¶”ê°€
        add_title_text(slide, header_info, prs)

        # ì´ë¯¸ì§€ ì¶”ê°€
        crop_image_path = header_info.get("crop_image_path")
        print(f"Checking image path: {crop_image_path}")

        if crop_image_path:
            if os.path.exists(crop_image_path):
                print(f"Image file exists: {crop_image_path}")
                try:
                    # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
                    with Image.open(crop_image_path) as img:
                        img_width, img_height = img.size
                        print(f"Image size: {img_width}x{img_height}")

                        # ìŠ¬ë¼ì´ë“œ í¬ê¸°
                        slide_width = prs.slide_width
                        slide_height = prs.slide_height

                        # ì´ë¯¸ì§€ë¥¼ ìŠ¬ë¼ì´ë“œ ì¤‘ì•™ì— ë°°ì¹˜
                        # ìƒë‹¨ ì—¬ë°± (ì œëª© ì•„ë˜)
                        top_margin = Inches(2.0)
                        # í•˜ë‹¨ ì—¬ë°± (ì¶œì²˜ í…ìŠ¤íŠ¸ ìœ„)
                        bottom_margin = Inches(1.5)
                        # ì‚¬ìš© ê°€ëŠ¥í•œ ë†’ì´
                        available_height = slide_height - top_margin - bottom_margin

                        # ì´ë¯¸ì§€ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
                        img_ratio = img_width / img_height

                        # ë†’ì´ ê¸°ì¤€ìœ¼ë¡œ í¬ê¸° ê³„ì‚°
                        height = available_height
                        width = height * img_ratio

                        # ë„ˆë¹„ê°€ ìŠ¬ë¼ì´ë“œ ë„ˆë¹„ì˜ 90%ë¥¼ ë„˜ìœ¼ë©´ ë„ˆë¹„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ê³„ì‚°
                        if width > slide_width * 0.9:
                            width = slide_width * 0.9
                            height = width / img_ratio

                        # ì´ë¯¸ì§€ ìœ„ì¹˜ ê³„ì‚° (ì¤‘ì•™ ì •ë ¬)
                        left = (slide_width - width) / 2
                        top = top_margin + (available_height - height) / 2

                        print(
                            f"Adding image at: left={left}, top={top}, width={width}, height={height}"
                        )
                        slide.shapes.add_picture(
                            crop_image_path, left, top, width, height
                        )
                        print("Image added successfully")
                except Exception as e:
                    print(f"Error adding image: {str(e)}")
                    import traceback

                    print(traceback.format_exc())
            else:
                print(f"Image file does not exist: {crop_image_path}")
        else:
            print("No image path in header info")

        # ì¶œì²˜ í…ìŠ¤íŠ¸ ì¶”ê°€
        add_source_text(slide, header_info, prs, "êµë³´ë§ˆì´í”Œëœê±´ê°•ë³´í—˜")

        # AI ê³ ì§€ ë¬¸êµ¬ ì¶”ê°€
        add_ai_notice_text(slide, prs)

    # PPT ì €ì¥
    print(f"\nSaving PPT to: {output_path}")
    try:
        prs.save(output_path)
        print("PPT saved successfully")
    except Exception as e:
        print(f"Error saving PPT: {str(e)}")
        import traceback

        print(traceback.format_exc())

    return output_path


def get_deepest_header_and_level(metadata):
    """ë©”íƒ€ë°ì´í„°ì—ì„œ ê°€ì¥ ê¹Šì€ ë ˆë²¨ì˜ í—¤ë”ë¥¼ ì°¾ë˜, ì‹¤ì œ í—¤ë” ë ˆë²¨ì„ ë°˜í™˜"""
    # ë¨¼ì € Header 1ë¶€í„° Header 3ê¹Œì§€ í™•ì¸
    for depth in range(1, 4):  # 1ë¶€í„° 3ê¹Œì§€ ìˆœì°¨ì ìœ¼ë¡œ í™•ì¸
        key = f"Header {depth}"
        if key in metadata and metadata[key]:
            # ì‹¤ì œ í—¤ë” ë ˆë²¨ì„ ì°¾ê¸° ìœ„í•´ header_dict í™•ì¸
            header_text = metadata[key]
            for h in st.session_state.get("header_dict", {}).values():
                # í…ìŠ¤íŠ¸ ë¹„êµ ì‹œ ê³µë°± ì œê±°í•˜ê³  ì •ê·œí™”
                if h["text"].strip() == header_text.strip():
                    return header_text, h["level"]  # ì‹¤ì œ í—¤ë” ë ˆë²¨ ë°˜í™˜
    return None, None


def convert_pdf_to_images(pdf_path, output_dir):
    """PDF íŒŒì¼ì„ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥ (1í˜ì´ì§€ ì œì™¸)"""
    try:
        import fitz  # PyMuPDF

        print(f"Converting PDF to images: {pdf_path}")

        # PDF ì—´ê¸°
        doc = fitz.open(pdf_path)
        total_pages = len(doc)
        print(f"Total pages: {total_pages}")

        # 2í˜ì´ì§€ë¶€í„° ì‹œì‘ (1í˜ì´ì§€ ì œì™¸)
        for page_num in range(1, total_pages):  # 1ë¶€í„° ì‹œì‘í•˜ì—¬ 1í˜ì´ì§€ ì œì™¸
            page = doc[page_num]
            # DPIë¥¼ 300ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±
            pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72))
            output_path = os.path.join(
                output_dir, f"page_{page_num + 1}.jpg"
            )  # page_num + 1ë¡œ íŒŒì¼ëª… ìœ ì§€
            pix.save(output_path)
            print(f"Saved page {page_num + 1} as image: {output_path}")

        doc.close()
        return True
    except Exception as e:
        print(f"Error converting PDF to images: {str(e)}")
        import traceback

        print(traceback.format_exc())
        return False


# 2ë‹¨ ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ (ì™¼ìª½: ì±„íŒ…, ì˜¤ë¥¸ìª½: íŒŒì¼ ì—…ë¡œë“œ)
col_chat, col_upload = st.columns([2, 1])

# FAISS DBë¥¼ ì„¸ì…˜ì— ì €ì¥
if "faiss_db" not in st.session_state:
    st.session_state["faiss_db"] = None

with col_chat:
    st.header("ğŸ’¬ êµìœ¡ ìë£Œ ìƒì„±í•˜ê¸°")
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []
    # ì±„íŒ… ë‚´ì—­ í‘œì‹œ
    for msg in st.session_state["chat_history"]:
        st.markdown(f"**{msg['role']}**: {msg['content']}")
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="user_input")

    # ê²€ìƒ‰ ë²„íŠ¼ ë° ê²°ê³¼ ì¶œë ¥
    if st.button("ê²€ìƒ‰"):
        if st.session_state["faiss_db"] is not None and user_input:
            header_dict = st.session_state.get("header_dict", {})
            retriever = st.session_state["faiss_db"].as_retriever(
                search_type="similarity", search_kwargs={"k": 3}
            )
            results = retriever.invoke(user_input)
            st.subheader("ê²€ìƒ‰ ê²°ê³¼")
            for i, doc in enumerate(results):
                page = doc.metadata.get("page_number", "ì•Œ ìˆ˜ ì—†ìŒ")
                st.markdown(f"**ê²°ê³¼ {i+1} (í˜ì´ì§€: {page})**")
                st.code(doc.page_content)
                # === ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° ì¶”ê°€ ===
                header_text, level = get_deepest_header_and_level(doc.metadata)
                matched_header = None
                for h in header_dict.values():
                    if (
                        h["page"] == page
                        and h["level"] == level
                        and h["text"] == header_text
                    ):
                        matched_header = h
                        break
                if (
                    matched_header
                    and matched_header.get("crop_image_path")
                    and os.path.exists(matched_header["crop_image_path"])
                ):
                    st.image(
                        matched_header["crop_image_path"],
                        caption=f"ì´ë¯¸ì§€ ({header_text})",
                        use_column_width=True,
                    )

            # === ê²€ìƒ‰ ê²°ê³¼ PPT ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ===
            selected_headers = []

            for doc in results:
                page = doc.metadata.get("page_number")
                header_text, level = get_deepest_header_and_level(doc.metadata)
                for h in header_dict.values():
                    if (
                        h["page"] == page
                        and h["level"] == level
                        and h["text"].strip() == header_text.strip()
                    ):
                        selected_headers.append(h)
                        break

            st.session_state["selected_headers"] = selected_headers
            # ê²€ìƒ‰ ì‹œì ì— PPTë¥¼ ë¯¸ë¦¬ ìƒì„±í•˜ê³  ê²½ë¡œë¥¼ ì„¸ì…˜ì— ì €ì¥
            pptx_path = os.path.join("temp_output", "search_results.pptx")

            if selected_headers:
                # selected_headersë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
                selected_headers_dict = {}
                for header in selected_headers:
                    if header.get("text") and header.get("crop_image_path"):
                        selected_headers_dict[header["text"]] = header

                if selected_headers_dict:
                    create_ppt_from_header_dict(selected_headers_dict, pptx_path)
                    st.session_state["search_pptx_path"] = pptx_path
                else:
                    st.session_state["search_pptx_path"] = None
            else:
                st.session_state["search_pptx_path"] = None

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì€ ì„¸ì…˜ ê°’ë§Œ ì‚¬ìš©
            if st.session_state.get("search_pptx_path") and os.path.exists(
                st.session_state["search_pptx_path"]
            ):
                with open(st.session_state["search_pptx_path"], "rb") as f:
                    st.download_button(
                        label="ê²€ìƒ‰ ê²°ê³¼ PPT ë‹¤ìš´ë¡œë“œ",
                        data=f,
                        file_name="search_results.pptx",
                        mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                    )
            else:
                st.info("ê²€ìƒ‰ ê²°ê³¼ì— í•´ë‹¹í•˜ëŠ” í—¤ë” ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë¨¼ì € ë²¡í„°ìŠ¤í† ì–´ì— ì„ë² ë”©ì„ ì €ì¥í•˜ê³ , ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

with col_upload:
    st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])
    if uploaded_file:
        st.info("íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ íŒŒì‹±ì„ ì‹œì‘í•˜ì„¸ìš”.")
        output_dir = "temp_output"
        os.makedirs(output_dir, exist_ok=True)
        md_save_path = os.path.join(
            output_dir, f"temp_{os.path.splitext(uploaded_file.name)[0]}.md"
        )
        pptx_path = os.path.join(output_dir, "exported_slides.pptx")
        progress_bar = st.progress(0, text="ëŒ€ê¸° ì¤‘...")
        status_text = st.empty()
        if "parsing_in_progress" not in st.session_state:
            st.session_state["parsing_in_progress"] = False
        if not st.session_state["parsing_in_progress"]:
            if ("pptx_path" in st.session_state and st.session_state["pptx_path"]) or (
                "md_save_path" in st.session_state and st.session_state["md_save_path"]
            ):
                st.success("íŒŒì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
                pptx_path = st.session_state.get("pptx_path")
                md_save_path = st.session_state.get("md_save_path")
                if pptx_path:
                    try:
                        with open(pptx_path, "rb") as f:
                            st.download_button(
                                label="íŒŒì‹±ëœ PPT íŒŒì¼ ì „ì²´ ë‹¤ìš´ë¡œë“œ",
                                data=f,
                                file_name="exported_slides.pptx",
                                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                            )
                    except Exception as e:
                        st.error(f"PPT íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                if md_save_path:
                    try:
                        with open(md_save_path, "rb") as f_md:
                            st.download_button(
                                label="íŒŒì‹±ëœ Markdown íŒŒì¼ ì „ì²´ ë‹¤ìš´ë¡œë“œ",
                                data=f_md,
                                file_name=os.path.basename(md_save_path),
                                mime="text/markdown",
                            )
                    except Exception as e:
                        st.error(f"Markdown íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            else:
                if st.button("íŒŒì‹± ì‹œì‘", type="primary"):
                    # temp_output ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ ì‚­ì œ
                    for file in os.listdir(output_dir):
                        file_path = os.path.join(output_dir, file)
                        try:
                            if os.path.isfile(file_path):
                                os.remove(file_path)
                        except Exception as e:
                            print(f"Error deleting {file_path}: {e}")

                    st.session_state["parsing_in_progress"] = True
                    st.experimental_rerun()
        if st.session_state["parsing_in_progress"]:
            status_text.info("ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ë³€í™˜ì¤‘...")

            temp_pdf_path = os.path.join(output_dir, f"temp_{uploaded_file.name}")
            with open(temp_pdf_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” ì´ˆê¸° ë‹¨ê³„ ì œê±°
            progress_bar.progress(10, text="ë¬¸ì„œ íŒŒì‹± ì‹œì‘...")
            status_text.info("ë¬¸ì„œ íŒŒì‹± ì‹œì‘...")

            parser_obj = UpstageParser()
            result = parser_obj.parse(temp_pdf_path)

            # í˜ì´ì§€ë³„ë¡œ ìš”ì†Œë“¤ì„ ê·¸ë£¹í™”
            pages = {}
            for element in result.get("elements", []):
                page_num = element.get("page", 1)
                if page_num not in pages:
                    pages[page_num] = []
                pages[page_num].append(element)

            # í—¤ë” ì •ë³´ ì¶”ì¶œ (Upstage coordinates ì‚¬ìš©)
            headers = []

            # ê° í˜ì´ì§€ë³„ë¡œ ì²˜ë¦¬
            for page_num, page_elements in sorted(pages.items()):
                prev_was_heading = False
                consecutive_heading_count = 0  # ì—°ì†ëœ headingì˜ ê°œìˆ˜ ì¶”ì 
                first_heading_found = False  # í˜ì´ì§€ì˜ ì²« ë²ˆì§¸ heading ì¶”ì 
                previous_levels = set()  # ì´ì „ì— ë‚˜ì˜¨ heading levelë“¤ì„ ì¶”ì 

                for element in page_elements:
                    if element.get("category", "").startswith("heading"):
                        content = element.get("content", {})
                        text = content.get("markdown", "").strip()
                        text = re.sub(r"^#+\s*", "", text)

                        # í•œê¸€ì´ ì—†ëŠ” í—¤ë”(ìˆ«ì/ì˜ì–´/íŠ¹ìˆ˜ë¬¸ìë§Œ)ëŠ” ì œì™¸
                        if is_useless_header(text):
                            continue

                        # y ì¢Œí‘œ ê³„ì‚° (ìƒë‹¨ ë‘ ì¢Œí‘œì˜ í‰ê· )
                        coordinates = element.get("coordinates", [])
                        y_coord = None
                        if coordinates and len(coordinates) >= 4:
                            top_y_coords = [coord["y"] for coord in coordinates[:2]]
                            y_coord = sum(top_y_coords) / len(top_y_coords)

                        # heading level ê²°ì • ë¡œì§
                        if not first_heading_found:
                            # í˜ì´ì§€ì˜ ì²« ë²ˆì§¸ headingì€ í•­ìƒ level 1
                            final_level = 1
                            first_heading_found = True
                            consecutive_heading_count = 1
                        elif not prev_was_heading:
                            # ë³¸ë¬¸(headingì´ ì•„ë‹˜) ì´í›„ì˜ heading level ê²°ì •
                            if 3 in previous_levels:
                                final_level = 3
                            elif 2 in previous_levels:
                                final_level = 2
                            else:
                                final_level = 2
                            consecutive_heading_count = final_level
                        else:
                            # ì´ì „ ìš”ì†Œê°€ headingì´ì—ˆë‹¤ë©´ level ì¦ê°€
                            consecutive_heading_count += 1
                            final_level = min(
                                consecutive_heading_count, 3
                            )  # ìµœëŒ€ level 3

                        # í˜„ì¬ levelì„ previous_levelsì— ì¶”ê°€
                        previous_levels.add(final_level)

                        # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í…ìŠ¤íŠ¸ ìƒì„±
                        markdown_text = "#" * (final_level - 1) + " " + text

                        headers.append(
                            {
                                "page": page_num,
                                "level": final_level,
                                "text": text,
                                "markdown_text": markdown_text,
                                "y": y_coord,
                            }
                        )
                        prev_was_heading = True
                    else:
                        prev_was_heading = False

            # í—¤ë” ë”•ì…”ë„ˆë¦¬ ìƒì„±
            header_dict = build_header_dictionary(headers, {}, output_dir=output_dir)
            st.session_state["header_dict"] = header_dict

            # ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
            md_docs = []
            current_doc = []

            # í˜ì´ì§€ë³„ë¡œ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
            for page_num, page_elements in sorted(pages.items()):
                page_content = []
                for element in page_elements:
                    category = element.get("category", "")
                    content = element.get("content", {})

                    if category.startswith("heading"):
                        # í—¤ë”ì¸ ê²½ìš°
                        text = content.get("markdown", "").strip()
                        # # ê¸°í˜¸ ì œê±°
                        text = re.sub(r"^#+\s*", "", text)

                        # header_dictì—ì„œ í•´ë‹¹ í—¤ë”ì˜ ì‹¤ì œ ë ˆë²¨ ì‚¬ìš©
                        if text in header_dict:
                            header_info = header_dict[text]
                            level = header_info["level"]
                            page_content.append(f"{'#' * (level)}{" "}{text}")
                            print(f"[í—¤ë” ë§¤ì¹­] '{text}' -> Level {level}")
                        else:
                            print(f"[í—¤ë” ë§¤ì¹­ ì‹¤íŒ¨] '{text}'")
                    else:
                        # ë³¸ë¬¸ì¸ ê²½ìš°
                        text = content.get("markdown", "").strip()
                        if text:
                            page_content.append(text)

                # í˜ì´ì§€ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
                if page_content:
                    md_docs.append("\n".join(page_content))

            st.session_state["md_docs"] = md_docs
            st.session_state["upstage_parse_result"] = result
            progress_bar.progress(40, text="ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„± ì™„ë£Œ!")
            status_text.success("ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„± ì™„ë£Œ!")

            # md_docsë¥¼ íŒŒì¼ë¡œ ì €ì¥
            md_save_path = os.path.join(output_dir, "parsed_docs.md")
            with open(md_save_path, "w", encoding="utf-8") as f:
                for doc in md_docs:
                    f.write(doc + "\n\n")
            st.session_state["md_save_path"] = md_save_path

            progress_bar.progress(50, text="ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ì¤‘...")
            status_text.info("ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ì¤‘...")

            # ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            headers_to_split_on = [
                ("##", "Header 2"),  # Header 1 ì œì™¸
                ("###", "Header 3"),
            ]
            markdown_splitter = MarkdownHeaderTextSplitter(
                headers_to_split_on=headers_to_split_on
            )
            all_chunks = []
            md_docs = st.session_state.get("md_docs", [])

            # chunk ìƒì„± ë¡œê¹…
            print("\n=== Chunk ìƒì„± ìš”ì•½ ===")
            total_chunks = 0
            for page_num, doc in enumerate(md_docs, 1):
                chunks = markdown_splitter.split_text(doc)
                total_chunks += len(chunks)
                print(f"í˜ì´ì§€ {page_num}: {len(chunks)}ê°œ chunk")

                # ê° chunkì˜ í—¤ë” ì •ë³´ë§Œ ê°„ë‹¨íˆ ì¶œë ¥
                for chunk in chunks:
                    headers = [
                        f"{k}: {v}"
                        for k, v in chunk.metadata.items()
                        if k.startswith("Header")
                    ]
                    if headers:
                        print(f"  - {headers[0]}")
                    chunk.metadata["page_number"] = page_num

                # chunksë¥¼ all_chunksì— ì¶”ê°€
                all_chunks.extend(chunks)

            print(f"\nì´ {total_chunks}ê°œ chunk ìƒì„± ì™„ë£Œ (Header 1 ì œì™¸)")
            print("=====================\n")

            progress_bar.progress(70, text="ì„ë² ë”© ê³„ì‚°ì¤‘...")
            embeddings = OpenAIEmbeddings()
            db = FAISS.from_documents(all_chunks, embeddings)
            st.session_state["faiss_db"] = db

            progress_bar.progress(80, text="í—¤ë” ì •ë³´ ì²˜ë¦¬ì¤‘...")
            status_text.info("í—¤ë” ì •ë³´ ì²˜ë¦¬ì¤‘...")

            # íŒŒì‹±ì´ ëë‚œ ì§í›„ ìµœì‹  header_dictë¡œ PPT ìƒì„±
            create_ppt_from_header_dict(header_dict, pptx_path)
            # header_dictë¥¼ í‘œë¡œ ì‹œê°í™”
            df = pd.DataFrame(list(header_dict.values()))
            st.subheader("íŒŒì‹±ëœ ì£¼ì œë³„ ì •ë³´ í‘œ")
            st.dataframe(df)
            progress_bar.progress(100, text="ìƒì„± ì™„ë£Œ!")
            status_text.success("ëª¨ë“  íŒŒì¼ì´ íŒŒì‹±ëœ PPT ìƒì„± ì™„ë£Œ!")
            st.session_state["pptx_path"] = pptx_path
            st.session_state["parsing_in_progress"] = False
            # íŒŒì‹± ì§í›„ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë°”ë¡œ ë…¸ì¶œ
            st.success("íŒŒì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
            pptx_path = st.session_state.get("pptx_path")
            md_save_path = st.session_state.get("md_save_path")
            if pptx_path:
                try:
                    with open(pptx_path, "rb") as f:
                        st.download_button(
                            label="íŒŒì‹±ëœ PPT íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                            data=f,
                            file_name="exported_slides.pptx",
                            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                        )
                except Exception as e:
                    st.error(f"PPT íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            if md_save_path:
                try:
                    with open(md_save_path, "rb") as f_md:
                        st.download_button(
                            label="íŒŒì‹±ëœ Markdown íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                            data=f_md,
                            file_name=os.path.basename(md_save_path),
                            mime="text/markdown",
                        )
                except Exception as e:
                    st.error(f"Markdown íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
