import streamlit as st
import os
from dotenv import load_dotenv
import nest_asyncio
import re
from PIL import Image

nest_asyncio.apply()
from llama_cloud_services import LlamaParse
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
import openai
import json
from scripts.clova_ocr_utils import ocr_image
import requests
import time

# .env í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

st.set_page_config(page_title="PDF Chat App", layout="wide")

# 2ë‹¨ ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ (ì™¼ìª½: ì±„íŒ…, ì˜¤ë¥¸ìª½: íŒŒì¼ ì—…ë¡œë“œ)
col_chat, col_upload = st.columns([2, 1])

# FAISS DBë¥¼ ì„¸ì…˜ì— ì €ì¥
if "faiss_db" not in st.session_state:
    st.session_state["faiss_db"] = None

with col_chat:
    st.header("ğŸ’¬ êµìœ¡ ìë£Œ ìƒì„±í•˜ê¸°")
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []
    # ì±„íŒ… ë‚´ì—­ í‘œì‹œ
    for msg in st.session_state["chat_history"]:
        st.markdown(f"**{msg['role']}**: {msg['content']}")
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="user_input")

    # ê²€ìƒ‰ ë²„íŠ¼ ë° ê²°ê³¼ ì¶œë ¥
    if st.button("ê²€ìƒ‰"):
        if st.session_state["faiss_db"] is not None and user_input:
            retriever = st.session_state["faiss_db"].as_retriever(
                search_type="similarity", search_kwargs={"k": 3}
            )
            results = retriever.invoke(user_input)
            st.subheader("ê²€ìƒ‰ ê²°ê³¼")
            if isinstance(results, list):
                for i, doc in enumerate(results):
                    page = doc.metadata.get("page_number", "ì•Œ ìˆ˜ ì—†ìŒ")
                    st.markdown(f"**ê²°ê³¼ {i+1} (í˜ì´ì§€: {page})**")
                    st.code(doc.page_content)
                    st.json(doc.metadata)
            else:
                page = results.metadata.get("page_number", "ì•Œ ìˆ˜ ì—†ìŒ")
                st.markdown(f"**ê²°ê³¼ (í˜ì´ì§€: {page})**")
                st.code(results.page_content)
                st.json(results.metadata)
        else:
            st.warning("ë¨¼ì € FAISSì— ì„ë² ë”©ì„ ì €ì¥í•˜ê³ , ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

with col_upload:
    st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])
    if uploaded_file:
        st.info("íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ íŒŒì‹±ì„ ì‹œì‘í•˜ì„¸ìš”.")
        output_dir = "temp_output"
        os.makedirs(output_dir, exist_ok=True)
        md_save_path = os.path.join(
            output_dir, f"temp_{os.path.splitext(uploaded_file.name)[0]}.md"
        )
        # ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì¬í™œìš© ë¡œì§ ì œê±°: í•­ìƒ ìƒˆë¡œ íŒŒì‹±
        if st.button("íŒŒì‹± ì‹œì‘"):
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_pdf_path = os.path.join(output_dir, f"temp_{uploaded_file.name}")
            with open(temp_pdf_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            # llama parser ì‹¤í–‰
            parser_obj = LlamaParse(
                api_key=os.getenv("LLAMA_CLOUD_API_KEY"),
                num_workers=1,
                verbose=True,
                language="ko",
                extract_layout=True,
                premium_mode=True,
                continuous_mode=False,
                extract_charts=True,
                save_images=True,
                output_tables_as_HTML=False,
                max_pages=7,
            )
            st.info("llama_parse ì‹¤í–‰ ì¤‘...")
            result = parser_obj.parse(temp_pdf_path)
            # split_by_page=Trueë¡œ md_docs ìƒì„±
            md_docs = result.get_markdown_documents(split_by_page=True)
            st.session_state["md_docs"] = md_docs  # ì„¸ì…˜ì— ì €ì¥
            st.session_state["llama_parse_result"] = result
            st.success("ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„± ì™„ë£Œ!")
            # === ëª¨ë“  í˜ì´ì§€ì˜ full_page_screenshot ì €ì¥ ===
            for page in result.pages:
                images = getattr(page, "images", [])
                for img in images:
                    if getattr(img, "type", None) == "full_page_screenshot":
                        img_name = getattr(img, "name", None)
                        if img_name:
                            result.save_image(img_name, output_dir)
            # ===
            if md_docs:
                # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
                with open(md_save_path, "w", encoding="utf-8") as f:
                    for doc in md_docs:
                        f.write(doc.text)
                st.session_state["md_save_path"] = md_save_path
                st.info(f"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {md_save_path}")
        elif "md_docs" in st.session_state:
            st.success("ì´ì „ íŒŒì‹± ê²°ê³¼:")
            # ë¯¸ë¦¬ë³´ê¸°ëŠ” ì œê³µí•˜ì§€ ì•ŠìŒ

    # ì„ë² ë”© ë° FAISS ì €ì¥ ë²„íŠ¼
    if "md_save_path" in st.session_state and st.button("ì„ë² ë”© ë° FAISS ì €ì¥"):
        md_save_path = st.session_state["md_save_path"]
        with open(md_save_path, "r", encoding="utf-8") as f:
            md_text = f.read()
        # 1. Split (í˜ì´ì§€ë³„ë¡œ)
        headers_to_split_on = [
            ("#", "Header 1"),
            ("##", "Header 2"),
            ("###", "Header 3"),
        ]
        markdown_splitter = MarkdownHeaderTextSplitter(
            headers_to_split_on=headers_to_split_on
        )
        all_chunks = []
        md_docs = st.session_state.get("md_docs", [])
        for doc in md_docs:
            chunks = markdown_splitter.split_text(doc.text)
            for chunk in chunks:
                chunk.metadata["page_number"] = doc.metadata.get("page_number")
            all_chunks.extend(chunks)
        # 2. ì„ë² ë”©
        embeddings = OpenAIEmbeddings()
        # 3. FAISS ë²¡í„° DB ì €ì¥
        db = FAISS.from_documents(all_chunks, embeddings)
        st.session_state["faiss_db"] = db  # ì„¸ì…˜ì— ì €ì¥
        st.success(
            f"{len(all_chunks)}ê°œ chunkê°€ ì„ë² ë”©ë˜ì–´ FAISSì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )


def find_header_y_from_ocr(image_path, header_text, api_url, secret_key):
    """
    CLOVA OCR ê²°ê³¼ì—ì„œ header_textì™€ ê°€ì¥ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ì˜ yì¢Œí‘œ ë°˜í™˜
    """
    ocr_result = ocr_image(image_path, api_url, secret_key)
    best_y = None
    best_score = 0
    for field in ocr_result["images"][0]["fields"]:
        text = field["inferText"]
        bbox = field["boundingPoly"]["vertices"]
        if header_text in text:
            y_top = min(v["y"] for v in bbox)
            return y_top, text, bbox
    return None, None, None


def clova_ocr_multipart(image_path, api_url, secret_key):
    """
    CLOVA OCR General APIë¥¼ multipart/form-data ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
    :param image_path: ì—…ë¡œë“œí•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    :param api_url: CLOVA OCR API Gateway Invoke URL
    :param secret_key: CLOVA OCR Secret Key
    :return: OCR ê²°ê³¼(JSON)
    """
    headers = {"X-OCR-SECRET": secret_key}

    files = {
        "file": open(image_path, "rb"),
        "message": (
            None,
            '{"version": "V2", "requestId": "1234", "timestamp": 1722225600000, "lang": "ko", "images": [{"format": "jpg", "name": "page_7.jpg"}]}',
        ),
    }

    response = requests.post(
        api_url,
        headers=headers,
        files=files,
    )
    response.raise_for_status()
    return response.json()


def normalize_text(text):
    # í•œê¸€ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±° (ìˆ«ì, ì˜ì–´, íŠ¹ìˆ˜ë¬¸ì, ë„ì–´ì“°ê¸° ëª¨ë‘ ì œê±°)
    return re.sub(r"[^ê°€-í£]", "", text)


def scale_ocr_y_to_image_y(ocr_y, ocr_result, image_path):
    img = Image.open(image_path)
    img_width, img_height = img.size
    st.warning(img_height)
    ocr_height = ocr_result["images"][0]["convertedImageInfo"]["height"]
    st.warning(ocr_height)
    return (ocr_y / ocr_height) * img_height


def extract_header_y_from_ocr_response(
    ocr_response, header_text, x_gap_threshold=40, image_path=None
):
    fields = ocr_response["images"][0]["fields"]
    lines = []
    current_line = []
    prev_field = None
    for field in fields:
        if not current_line:
            current_line.append(field)
        else:
            prev_right_x = max(v["x"] for v in prev_field["boundingPoly"]["vertices"])
            curr_left_x = min(v["x"] for v in field["boundingPoly"]["vertices"])
            if curr_left_x - prev_right_x > x_gap_threshold:
                lines.append(current_line)
                current_line = [field]
            else:
                current_line.append(field)
        prev_field = field
        if field.get("lineBreak", False):
            lines.append(current_line)
            current_line = []
            prev_field = None
    if current_line:
        lines.append(current_line)

    norm_header = normalize_text(header_text)
    # === ì˜ˆì™¸ ì²˜ë¦¬: 'ì•”ì§„ë‹¨' -> 'ì‚¼ì§„ë‹¨', 'ì•”ì¹˜ë£Œ' -> 'ì°¸ì¹˜ë£Œ' ===
    ocr_compare_header = norm_header
    if norm_header == "ì•”ì§„ë‹¨":
        ocr_compare_header = "ì‚¼ì§„ë‹¨"
    elif norm_header == "ì•”ì¹˜ë£Œ":
        ocr_compare_header = "ì°¸ì¹˜ë£Œ"
    # =====================================================
    strict_headers = {"ìˆ˜ìˆ ", "ì…ì›", "ì¬í•´"}
    for line_fields in lines:
        line_text = "".join(f["inferText"] for f in line_fields)
        norm_line = normalize_text(line_text)
        if norm_header in strict_headers:
            # ì˜ˆì™¸: ì™„ì „ ì¼ì¹˜ë§Œ í—ˆìš©
            if norm_line == norm_header:
                all_y = [
                    v["y"] for f in line_fields for v in f["boundingPoly"]["vertices"]
                ]
                y_top = min(all_y)
                bbox_list = [f["boundingPoly"]["vertices"] for f in line_fields]
                if image_path is not None:
                    y_top_scaled = scale_ocr_y_to_image_y(
                        y_top, ocr_response, image_path
                    )
                    return y_top_scaled, line_text, bbox_list
                else:
                    return y_top, line_text, bbox_list
        else:
            # ì¼ë°˜: ë¶€ë¶„ ë¬¸ìì—´ + ë¼ì¸ ê¸¸ì´ ì œí•œ
            if norm_header in norm_line and len(norm_line) <= len(norm_header) * 1.5:
                all_y = [
                    v["y"] for f in line_fields for v in f["boundingPoly"]["vertices"]
                ]
                y_top = min(all_y)
                bbox_list = [f["boundingPoly"]["vertices"] for f in line_fields]
                if image_path is not None:
                    y_top_scaled = scale_ocr_y_to_image_y(
                        y_top, ocr_response, image_path
                    )
                    return y_top_scaled, line_text, bbox_list
                else:
                    return y_top, line_text, bbox_list
    return None, None, None


def crop_image_by_y(image_path, y_start, y_end, output_path):
    img = Image.open(image_path)
    img_width, img_height = img.size
    y_start = int(max(0, y_start - 15))
    y_end = int(min(img_height, y_end))
    x_start = max(0, 30)
    x_end = min(img_width, img_width - 30)
    if y_end <= y_start or x_end <= x_start:
        return None  # ë¹ˆ ì´ë¯¸ì§€ ë°©ì§€
    cropped = img.crop((x_start, y_start, x_end, y_end))
    cropped.save(output_path)
    return output_path


# ì‚¬ìš© ì˜ˆì‹œ (Streamlit sidebarì—ì„œ í…ŒìŠ¤íŠ¸)
if st.sidebar.button("í…ŒìŠ¤íŠ¸: í—¤ë” yì¢Œí‘œ ì°¾ê¸° (CLOVA OCR, multipart)"):
    test_meta = {
        "Header 1": "ë¯¸ë¦¬ ì²´í¬í•´ë³´ëŠ” êµë³´ë§ˆì´í”Œëœê±´ê°•ë³´í—˜[2411](ë¬´ë°°ë‹¹)",
        "Header 2": "ì°¸ì¹˜ë£Œ",  # ì•”ì§„ë‹¨ ì•”ì¹˜ë£Œ ìˆ˜ìˆ  ì…ì› ì¬í•´
        "page_number": 7,
        # ì•”ì¹˜ë£Œ - ì°¸ì¹˜ë£Œ
    }
    st.write(test_meta)
    page_img_path = os.path.join("temp_output", f"page_{test_meta['page_number']}.jpg")
    api_url = "https://8vb79ndbzb.apigw.ntruss.com/custom/v1/41373/3a26df9469f0c22bb024a70d5cc5e11a9fb28f6ea21993ba8eee769f4dda9216/general"
    secret_key = os.getenv("CLOVA_OCR_SECRET_KEY")
    st.write(page_img_path, api_url, secret_key)
    try:
        ocr_result = clova_ocr_multipart(page_img_path, api_url, secret_key)
        st.write(ocr_result)
        # í—¤ë” ìœ„ì¹˜ ì°¾ê¸°
        header_text = test_meta["Header 2"]
        y, matched_text, bbox = extract_header_y_from_ocr_response(
            ocr_result, header_text, image_path=page_img_path
        )
        if y is not None:
            st.sidebar.success(f"í—¤ë” '{header_text}'ì˜ yì¢Œí‘œ: {y}")
            st.sidebar.write(f"ë§¤ì¹­ëœ í…ìŠ¤íŠ¸: {matched_text}")
            st.sidebar.write(f"bbox: {bbox}")
            # === ì´ë¯¸ì§€ crop ===
            img = Image.open(page_img_path)
            img_height = img.size[1]
            y_start = y
            y_end = img_height  # ì˜ˆì‹œ: í—¤ë”ë¶€í„° ëê¹Œì§€ crop
            cropped_path = os.path.join(
                "temp_output", f"page_{test_meta['page_number']}_cropped.jpg"
            )
            crop_image_by_y(page_img_path, y_start, y_end, cropped_path)
            st.sidebar.info(f"Cropëœ ì´ë¯¸ì§€ ì €ì¥: {cropped_path}")
            st.sidebar.image(cropped_path)
            # ===================
        else:
            st.sidebar.error("í—¤ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.sidebar.error(f"OCR í˜¸ì¶œ ì‹¤íŒ¨: {e}")


def extract_headers_from_llamaparse_items(items, page_number):
    """LlamaParse itemsì—ì„œ header(page, level, text) ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (object íƒ€ì… ëŒ€ì‘)"""
    headers = []
    for item in items:
        if getattr(item, "type", None) == "heading":
            headers.append(
                {
                    "page": page_number,
                    "level": getattr(item, "lvl", 1),
                    "text": getattr(item, "value", ""),
                }
            )
    return headers


def build_header_dictionary(headers, ocr_results_dict, output_dir="temp_output"):
    """
    headers: [{page, level, text}, ...]
    ocr_results_dict: {page_number: ocr_result, ...}
    return: {"header_text": {page, level, text, y, crop_image_path}}
    """
    header_dict = {}
    from collections import defaultdict

    # í˜ì´ì§€ë³„ë¡œ ê·¸ë£¹í™”
    page_to_headers = defaultdict(list)
    for header in headers:
        if header["y"] is not None:
            page_to_headers[header["page"]].append(header)
    for page_number, page_headers in page_to_headers.items():
        page_img_path = os.path.join(output_dir, f"page_{page_number}.jpg")
        img = Image.open(page_img_path)
        img_height = img.size[1]
        # levelë³„ë¡œ ê·¸ë£¹í™”
        level_to_headers = defaultdict(list)
        for h in page_headers:
            level_to_headers[h["level"]].append(h)
        for level, headers_in_level in level_to_headers.items():
            headers_in_level = sorted(headers_in_level, key=lambda h: h["y"])
            for i, header in enumerate(headers_in_level):
                y_start = header["y"]
                if i < len(headers_in_level) - 1:
                    y_end = headers_in_level[i + 1]["y"]
                else:
                    y_end = img_height
                if y_end <= y_start:
                    continue
                out_path = os.path.join(
                    output_dir,
                    f"page_{page_number}_level{level}_header_{i+1}_{header['text'][:10]}.jpg",
                )
                crop_image_by_y(page_img_path, y_start, y_end, out_path)
                key = f"{header['text']}"
                header_dict[key] = {
                    "page": page_number,
                    "level": level,
                    "text": header["text"],
                    "y": y_start,
                    "crop_image_path": out_path,
                }
    return header_dict


# í—¤ë” dictionary ìƒì„± Streamlit ë²„íŠ¼
if st.sidebar.button("ì „ì²´ íŒŒì¼ì„ PPT ë¡œ íŒŒì‹±"):
    result = st.session_state.get("llama_parse_result")
    if not result:
        st.sidebar.error("llama_parse ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        api_url = "https://8vb79ndbzb.apigw.ntruss.com/custom/v1/41373/3a26df9469f0c22bb024a70d5cc5e11a9fb28f6ea21993ba8eee769f4dda9216/general"
        secret_key = os.getenv("CLOVA_OCR_SECRET_KEY")
        headers = []
        ocr_results_dict = {}
        output_dir = "temp_output"
        for page_idx, page in enumerate(result.pages):
            page_number = getattr(page, "page", page_idx + 1)
            items = getattr(page, "items", [])
            page_headers = extract_headers_from_llamaparse_items(items, page_number)
            # OCR ê²°ê³¼ ë¯¸ë¦¬ ì €ì¥
            page_img_path = os.path.join(output_dir, f"page_{page_number}.jpg")
            ocr_results_dict[page_number] = clova_ocr_multipart(
                page_img_path, api_url, secret_key
            )
            # í—¤ë”ë³„ yì¢Œí‘œ ì¶”ì¶œ
            for header in page_headers:
                ocr_result = ocr_results_dict.get(page_number)
                y, matched_text, bbox_list = extract_header_y_from_ocr_response(
                    ocr_result, header["text"], image_path=page_img_path
                )
                header["y"] = y
            headers.extend(page_headers)
        header_dict = build_header_dictionary(
            headers, ocr_results_dict, output_dir=output_dir
        )
        st.session_state["header_dict"] = header_dict
        st.sidebar.success("í—¤ë” dictionary ìƒì„± ë° ì´ë¯¸ì§€ crop ì™„ë£Œ!")
        st.write(header_dict)
